{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "657faca0-c88f-4138-8c62-cf9974e0c894",
    "_uuid": "b30a120404b8e104774a292b45f0902e89acef68"
   },
   "source": [
    "# Transfer learning with pretrained Keras models\n",
    "\n",
    "Although Kernel resources were increased recently we still can not train useful CNNs without GPU. The original ImageNet set has quite a few different dog classes so we can reuse CNNs with pretrained ImageNet weights. Fortunately prediction is much faster (<1s/image) making it possible to run meaningful experiments with Kaggle Kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "d4c4a3a8-93af-4cd2-a95b-32a2526ac3a2",
    "_uuid": "151b0f031d10c081017bee0831d1e276148b413b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from os import listdir, makedirs\n",
    "from os.path import join, exists, expanduser\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications import xception\n",
    "from keras.applications import inception_v3\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "c60a6481-e35a-49fd-b1b3-4c74f4adc472",
    "_uuid": "928b27a4686daca6a69bcf74bb592c9e99393992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-17 14:11:06.527929\n"
     ]
    }
   ],
   "source": [
    "start = dt.datetime.now()\n",
    "print(start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9ed0e437-74af-4568-8d15-342e9adcdb5d",
    "_uuid": "21279ccec131b58e04cca5516041df6046693ec1"
   },
   "source": [
    "# Use Keras Pretrained Models dataset\n",
    "\n",
    "Kernels can't use network connection to download pretrained keras model weights.\n",
    "This dataset helps you to apply your favorite pretrained model in the Kaggle Kernel environment. \n",
    "You can find more details [here](https://www.kaggle.com/gaborfodor/keras-pretrained-models).\n",
    "\n",
    "We have to copy the pretrained models to the cache directory (~/.keras/models) where keras is looking for them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "d2bdd2f5-2395-43ef-a971-5472066a0d36",
    "_uuid": "4838c6bd2565ff67ce2c47ba014035c7f70a9018"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls ../input/keras-pretrained-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "482686db-3424-4b64-86b9-119563d77940",
    "_uuid": "ac04695a27c65eccb786d1e48fe229a3c1e288a8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cache_dir = expanduser(join('~', '.keras'))\n",
    "if not exists(cache_dir):\n",
    "    makedirs(cache_dir)\n",
    "models_dir = join(cache_dir, 'models')\n",
    "if not exists(models_dir):\n",
    "    makedirs(models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ed6bb30d-f37b-4662-a1c4-ed02974204aa",
    "_uuid": "463b5222d5affca14b75657257f0efeb40be4ea0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cp ../input/keras-pretrained-models/*notop* ~/.keras/models/\n",
    "!cp ../input/keras-pretrained-models/imagenet_class_index.json ~/.keras/models/\n",
    "!cp ../input/keras-pretrained-models/resnet50* ~/.keras/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c357ada4-644c-403a-ba61-0a84c9510a89",
    "_uuid": "7506ec54c661024a9636fb247f4a05473aa9982d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls ~/.keras/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "aa2e9829-2f0e-43ef-bc30-1023bca24579",
    "_uuid": "db9e42caac1312e22a6d4b0d3eec804c74e17e16",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls ../input/dog-breed-identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7024f870-2c6f-4b86-a64e-adab46e34c1b",
    "_uuid": "48c9f0e65f26fa26375dd32289f9c59bd1353d1a"
   },
   "source": [
    "# Use top 16 classes\n",
    "Using all the images would take more than the 1 hour kernel limit. Let's focus on the most frequent 16 breeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_cell_guid": "8bcb2bda-88dc-4ad8-9177-0c126401c3e1",
    "_uuid": "3f62e82d998e8b2ba3999542492e632c5083a901"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10222 10222\n",
      "10357 10357\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = 224\n",
    "NUM_CLASSES = 16\n",
    "SEED = 1987\n",
    "data_dir = ''\n",
    "labels = pd.read_csv(join(data_dir, 'labels.csv'))\n",
    "sample_submission = pd.read_csv(join(data_dir, 'sample_submission.csv'))\n",
    "print(len(listdir(join(data_dir, 'train'))), len(labels))\n",
    "print(len(listdir(join(data_dir, 'test'))), len(sample_submission))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "_cell_guid": "f55b18df-3698-4146-9157-913227416e21",
    "_uuid": "ab322ce7a697d43a883b1725c7f71bf4486fd5ed"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-5719e0699fa0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'breed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselected_breed_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rank'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'breed'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mlabels_pivot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'breed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'target'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSEED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36mrank\u001b[1;34m(self, method, ascending, na_option, pct, axis)\u001b[0m\n\u001b[0;32m   1904\u001b[0m         return self._cython_transform('rank', numeric_only=False,\n\u001b[0;32m   1905\u001b[0m                                       \u001b[0mties_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1906\u001b[1;33m                                       na_option=na_option, pct=pct, axis=axis)\n\u001b[0m\u001b[0;32m   1907\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1908\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mSubstitution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'groupby'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m_cython_transform\u001b[1;34m(self, how, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m   1023\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m                 result, names = self.grouper.transform(obj.values, how,\n\u001b[1;32m-> 1025\u001b[1;33m                                                        **kwargs)\n\u001b[0m\u001b[0;32m   1026\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, values, how, axis, **kwargs)\u001b[0m\n\u001b[0;32m   2628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2629\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2630\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cython_operation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'transform'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2632\u001b[0m     def _aggregate(self, result, counts, values, comp_ids, agg_func,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m_cython_operation\u001b[1;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[0;32m   2588\u001b[0m             result = self._transform(\n\u001b[0;32m   2589\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_numeric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2590\u001b[1;33m                 **kwargs)\n\u001b[0m\u001b[0;32m   2591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2592\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, result, values, comp_ids, transform_func, is_numeric, is_datetimelike, **kwargs)\u001b[0m\n\u001b[0;32m   2662\u001b[0m                                comp_ids, is_datetimelike, **kwargs)\n\u001b[0;32m   2663\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2664\u001b[1;33m             \u001b[0mtransform_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomp_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2666\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2478\u001b[0m                 \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2479\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mafunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m                 \u001b[1;31m# need to curry our sub-function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(func, a, b, c, d, **kwargs)\u001b[0m\n\u001b[0;32m   2429\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascending'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2430\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pct'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2431\u001b[1;33m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'na_option'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'keep'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2432\u001b[0m                 )\n\u001b[0;32m   2433\u001b[0m             }\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "selected_breed_list = list(labels.groupby('breed').count().sort_values(by='id', ascending=False).head(NUM_CLASSES).index)\n",
    "labels = labels[labels['breed'].isin(selected_breed_list)]\n",
    "labels['target'] = 1\n",
    "labels['rank'] = labels.groupby('breed').rank()['id']\n",
    "labels_pivot = labels.pivot('id', 'breed', 'target').reset_index().fillna(0)\n",
    "np.random.seed(seed=SEED)\n",
    "rnd = np.random.random(len(labels))\n",
    "train_idx = rnd < 0.8\n",
    "valid_idx = rnd >= 0.8\n",
    "y_train = labels_pivot[selected_breed_list].values\n",
    "ytr = y_train[train_idx]\n",
    "yv = y_train[valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_cell_guid": "c48fc864-d70f-4045-96eb-12de12c0ad41",
    "_uuid": "7d26cc67909b5bd70173b5f2ed8352b210e06fb3"
   },
   "outputs": [],
   "source": [
    "def read_img(img_id, train_or_test, size):\n",
    "    \"\"\"Read and resize image.\n",
    "    # Arguments\n",
    "        img_id: string\n",
    "        train_or_test: string 'train' or 'test'.\n",
    "        size: resize the original image.\n",
    "    # Returns\n",
    "        Image as numpy array.\n",
    "    \"\"\"\n",
    "    img = image.load_img(join(data_dir, train_or_test, '%s.jpg' % img_id), target_size=size)\n",
    "    img = image.img_to_array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e7ee34ac-0ad9-49dc-8558-0a3ae120b287",
    "_uuid": "3bfb773d8c0b538400978a63de6ea47d7fb5d4d5"
   },
   "source": [
    "# ResNet50 class predictions for example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "_cell_guid": "f0a4e5c1-02af-4689-9845-f0f77322fb46",
    "_uuid": "e48ddfeed10002d48a318c564921c6e9e5b3c5f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102858752/102853048 [==============================] - ETA: 2:04:4 - ETA: 1:11:0 - ETA: 1:16:5 - ETA: 1:01:0 - ETA: 52:17  - ETA: 45:5 - ETA: 42:4 - ETA: 39:5 - ETA: 40:1 - ETA: 33:0 - ETA: 29:3 - ETA: 27:0 - ETA: 22:4 - ETA: 20:3 - ETA: 18:2 - ETA: 16:2 - ETA: 15:3 - ETA: 14:0 - ETA: 12:5 - ETA: 11:5 - ETA: 10:4 - ETA: 9:5 - ETA: 9: - ETA: 8: - ETA: 8: - ETA: 7: - ETA: 7: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 6: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 5: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 4: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 3: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 59s - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 58 - ETA: 57 - ETA: 57 - ETA: 57 - ETA: 56 - ETA: 55 - ETA: 55 - ETA: 55 - ETA: 54 - ETA: 54 - ETA: 54 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 52 - ETA: 52 - ETA: 52 - ETA: 52 - ETA: 51 - ETA: 51 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 49 - ETA: 49 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 47 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 46 - ETA: 45 - ETA: 45 - ETA: 44 - ETA: 44 - ETA: 44 - ETA: 43 - ETA: 43 - ETA: 43 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 41 - ETA: 40 - ETA: 40 - ETA: 41 - ETA: 39 - ETA: 38 - ETA: 39 - ETA: 38 - ETA: 36 - ETA: 36 - ETA: 36 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 35 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 39s 0us/step\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'rank'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3062\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3063\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3064\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'rank'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-d05a65c836a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m111\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows_ncols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes_pad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbreed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rank'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'breed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2683\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2684\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2685\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2690\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2691\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2692\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2484\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2485\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2486\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2487\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4115\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3063\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3065\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'rank'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ResNet50(weights='imagenet')\n",
    "j = int(np.sqrt(NUM_CLASSES))\n",
    "i = int(np.ceil(1. * NUM_CLASSES / j))\n",
    "fig = plt.figure(1, figsize=(16, 16))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(i, j), axes_pad=0.05)\n",
    "for i, (img_id, breed) in enumerate(labels.loc[labels['rank'] == 1, ['id', 'breed']].values):\n",
    "    ax = grid[i]\n",
    "    img = read_img(img_id, 'train', (224, 224))\n",
    "    ax.imshow(img / 255.)\n",
    "    x = preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "    preds = model.predict(x)\n",
    "    _, imagenet_class_name, prob = decode_predictions(preds, top=1)[0][0]\n",
    "    ax.text(10, 180, 'ResNet50: %s (%.2f)' % (imagenet_class_name , prob), color='w', backgroundcolor='k', alpha=0.8)\n",
    "    ax.text(10, 200, 'LABEL: %s' % breed, color='k', backgroundcolor='w', alpha=0.8)\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0a2cd723-1859-4b36-b5af-897b7b501c9e",
    "_uuid": "3774760723fa28d44b3505c2047c1a0b3f32eb05"
   },
   "source": [
    "Preprocessing and prediction seems to be working. 75% accuracy on these 16 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5759352a-e324-468c-b0b9-b360962a823f",
    "_uuid": "dd270f61ff0278c9171592f4999513b460f8f262"
   },
   "source": [
    "# Extract VGG16 bottleneck features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "62de53fc-18b6-45f4-8ec3-14a3287b2015",
    "_uuid": "db4f7052673aa28ca7822b9030dba078a6afb878",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_SIZE = 224\n",
    "POOLING = 'avg'\n",
    "x_train = np.zeros((len(labels), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "for i, img_id in tqdm(enumerate(labels['id'])):\n",
    "    img = read_img(img_id, 'train', (INPUT_SIZE, INPUT_SIZE))\n",
    "    x = preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "    x_train[i] = x\n",
    "print('Train Images shape: {} size: {:,}'.format(x_train.shape, x_train.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ff0176f1-60a6-4487-9df4-438f3604e4b8",
    "_uuid": "11bfa7db44dc81846a939f2c5259b283bbb7f9e4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtr = x_train[train_idx]\n",
    "Xv = x_train[valid_idx]\n",
    "print((Xtr.shape, Xv.shape, ytr.shape, yv.shape))\n",
    "vgg_bottleneck = VGG16(weights='imagenet', include_top=False, pooling=POOLING)\n",
    "train_vgg_bf = vgg_bottleneck.predict(Xtr, batch_size=32, verbose=1)\n",
    "valid_vgg_bf = vgg_bottleneck.predict(Xv, batch_size=32, verbose=1)\n",
    "print('VGG train bottleneck features shape: {} size: {:,}'.format(train_vgg_bf.shape, train_vgg_bf.size))\n",
    "print('VGG valid bottleneck features shape: {} size: {:,}'.format(valid_vgg_bf.shape, valid_vgg_bf.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "68b9963a-e2cd-463c-8708-11d2685e0eb2",
    "_uuid": "8adbc32293a65ff184b659282e3c9a4a5eba64af"
   },
   "source": [
    "# LogReg on VGG bottleneck features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "90569f5c-b196-4104-9089-43d8b8ddd12b",
    "_uuid": "6af396744a3c6d41f8256f993e60389d67e2ab52",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\n",
    "logreg.fit(train_vgg_bf, (ytr * range(NUM_CLASSES)).sum(axis=1))\n",
    "valid_probs = logreg.predict_proba(valid_vgg_bf)\n",
    "valid_preds = logreg.predict(valid_vgg_bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c92cf2e3-bd0f-44f4-932a-8fec12bf95ea",
    "_uuid": "4213c70e4a252cfae11f792aad256664258bb6be",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Validation VGG LogLoss {}'.format(log_loss(yv, valid_probs)))\n",
    "print('Validation VGG Accuracy {}'.format(accuracy_score((yv * range(NUM_CLASSES)).sum(axis=1), valid_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dcf8bcd6-c73e-4677-a2a3-30bc1708dd96",
    "_uuid": "0c150ebe0b4cc2fe05acb28d0f5cb0b69ceaf730"
   },
   "source": [
    "Not bad, 90% accuracy for the top 16 classes. The multiclass classification with 120 classes is more difficult so these LogLoss/Accuracy scores does not translate to LB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c9e29a84-5cad-49d7-9290-5f7755cb1d43",
    "_uuid": "e8f19dc62979a04aaa396f9cd9b990751d372286"
   },
   "source": [
    "# Extract Xception bottleneck features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fe14c29b-42a0-45cb-a7a0-5f201c984ff6",
    "_uuid": "7e5f115592134a49b4997903ccc9e7497797be1e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_SIZE = 299\n",
    "POOLING = 'avg'\n",
    "x_train = np.zeros((len(labels), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "for i, img_id in tqdm(enumerate(labels['id'])):\n",
    "    img = read_img(img_id, 'train', (INPUT_SIZE, INPUT_SIZE))\n",
    "    x = xception.preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "    x_train[i] = x\n",
    "print('Train Images shape: {} size: {:,}'.format(x_train.shape, x_train.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "37a9f47a-9a17-43cd-99b3-7f89192ccf34",
    "_uuid": "1508b3285ea437bf24aa765c76ea56042d406034",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtr = x_train[train_idx]\n",
    "Xv = x_train[valid_idx]\n",
    "print((Xtr.shape, Xv.shape, ytr.shape, yv.shape))\n",
    "xception_bottleneck = xception.Xception(weights='imagenet', include_top=False, pooling=POOLING)\n",
    "train_x_bf = xception_bottleneck.predict(Xtr, batch_size=32, verbose=1)\n",
    "valid_x_bf = xception_bottleneck.predict(Xv, batch_size=32, verbose=1)\n",
    "print('Xception train bottleneck features shape: {} size: {:,}'.format(train_x_bf.shape, train_x_bf.size))\n",
    "print('Xception valid bottleneck features shape: {} size: {:,}'.format(valid_x_bf.shape, valid_x_bf.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "065777fc-0308-4526-823a-4915cd5024be",
    "_uuid": "a1bdd346837a8ad7fbbe1f9b5cb424a33055117d"
   },
   "source": [
    "# LogReg on Xception bottleneck features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dc8a93f1-1ee6-450d-90a3-8fa77f245b3b",
    "_uuid": "db34ba100fb8a524487ed0b91134b6e65102e3fb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\n",
    "logreg.fit(train_x_bf, (ytr * range(NUM_CLASSES)).sum(axis=1))\n",
    "valid_probs = logreg.predict_proba(valid_x_bf)\n",
    "valid_preds = logreg.predict(valid_x_bf)\n",
    "print('Validation Xception LogLoss {}'.format(log_loss(yv, valid_probs)))\n",
    "print('Validation Xception Accuracy {}'.format(accuracy_score((yv * range(NUM_CLASSES)).sum(axis=1), valid_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3fe2d11d-4b69-4bc1-b004-6fc84f56dd0e",
    "_uuid": "17e0f22ff8cea58ba198e5556c472b7dc6ed84a0"
   },
   "source": [
    "![](https://pics.me.me/such-wow-much-awesome-many-cool-bestest-thug-life-19337110.png)\n",
    "\n",
    "Much better! 98% accuracy 0.07 LogLoss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8ca30754-3b63-4c2a-a7ed-a111a4e0b837",
    "_uuid": "e17c08d790ef172e13900624df42d9ea9a43cc69"
   },
   "source": [
    "# Extract Inception bottleneck features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1c608857-0f1a-4132-b004-a1a3eda59d60",
    "_uuid": "5244f45ca3093adc9034a4115d309349f8b7bc1e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtr = x_train[train_idx]\n",
    "Xv = x_train[valid_idx]\n",
    "print((Xtr.shape, Xv.shape, ytr.shape, yv.shape))\n",
    "inception_bottleneck = inception_v3.InceptionV3(weights='imagenet', include_top=False, pooling=POOLING)\n",
    "train_i_bf = inception_bottleneck.predict(Xtr, batch_size=32, verbose=1)\n",
    "valid_i_bf = inception_bottleneck.predict(Xv, batch_size=32, verbose=1)\n",
    "print('InceptionV3 train bottleneck features shape: {} size: {:,}'.format(train_i_bf.shape, train_i_bf.size))\n",
    "print('InceptionV3 valid bottleneck features shape: {} size: {:,}'.format(valid_i_bf.shape, valid_i_bf.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d7930ef0-2d75-409c-88c7-b150f384a93e",
    "_uuid": "86550ce360964aa21f7cc70e1761132241e0cf55"
   },
   "source": [
    "# LogReg on Inception bottleneck features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "675864f8-7bfe-47d6-960e-d4bd686cf31a",
    "_uuid": "e36b51ff6bba98246c6f380fecc33680deff88c5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\n",
    "logreg.fit(train_i_bf, (ytr * range(NUM_CLASSES)).sum(axis=1))\n",
    "valid_probs = logreg.predict_proba(valid_i_bf)\n",
    "valid_preds = logreg.predict(valid_i_bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "655a9cfe-a2f2-4a8a-90d4-dac18cf72027",
    "_uuid": "8fe401e1ce9d41c617bd24045d4462a05f59eb88",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Validation Inception LogLoss {}'.format(log_loss(yv, valid_probs)))\n",
    "print('Validation Inception Accuracy {}'.format(accuracy_score((yv * range(NUM_CLASSES)).sum(axis=1), valid_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b7b3f4f3-f134-4b3c-aaa0-9d7dd01b4b98",
    "_uuid": "ea2d8acf56c3a2796c5923e3a75d3ac64d22bce7"
   },
   "source": [
    "# LogReg on all bottleneck features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1c858bb8-9d3a-4f30-8c07-e08726d471ac",
    "_uuid": "9356a162d8a39db89aab783d39c4012edd2a8ed5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.hstack([train_x_bf, train_i_bf])\n",
    "V = np.hstack([valid_x_bf, valid_i_bf])\n",
    "print('Full train bottleneck features shape: {} size: {:,}'.format(X.shape, X.size))\n",
    "print('Full valid bottleneck features shape: {} size: {:,}'.format(V.shape, V.size))\n",
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\n",
    "logreg.fit(X, (ytr * range(NUM_CLASSES)).sum(axis=1))\n",
    "valid_probs = logreg.predict_proba(V)\n",
    "valid_preds = logreg.predict(V)\n",
    "print('Validation Xception + Inception LogLoss {}'.format(log_loss(yv, valid_probs)))\n",
    "print('Validation Xception + Inception Accuracy {}'.format(accuracy_score((yv * range(NUM_CLASSES)).sum(axis=1), valid_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d6d917af-8c5a-4a06-ab3c-c7fb327e954e",
    "_uuid": "a8c185d2f7068a8d370aa239868d6a83b786960e"
   },
   "source": [
    "Training this model on the full dataset would give 0.3 LogLoss on LB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "28ac6c7c-99c0-4afa-b396-58a5524e6ebc",
    "_uuid": "646d482fb5c7b2a792abfbb6c05dd72a94f353a7"
   },
   "source": [
    "# Check errors\n",
    "We still have a few misclassification errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ff6da045-b279-4d49-a581-41fe6525b797",
    "_uuid": "17ae76c56f08f8602ce0456c9b14f33581da76d5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_breeds = (yv * range(NUM_CLASSES)).sum(axis=1)\n",
    "error_idx = (valid_breeds != valid_preds)\n",
    "for img_id, breed, pred in zip(labels.loc[valid_idx, 'id'].values[error_idx],\n",
    "                                [selected_breed_list[int(b)] for b in valid_preds[error_idx]],\n",
    "                                [selected_breed_list[int(b)] for b in valid_breeds[error_idx]]):\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    img = read_img(img_id, 'train', (299, 299))\n",
    "    ax.imshow(img / 255.)\n",
    "    ax.text(10, 250, 'Prediction: %s' % pred, color='w', backgroundcolor='r', alpha=0.8)\n",
    "    ax.text(10, 270, 'LABEL: %s' % breed, color='k', backgroundcolor='g', alpha=0.8)\n",
    "    ax.axis('off')\n",
    "    plt.show()                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "467d7924-aff9-4947-915c-77bc0a21ae13",
    "_uuid": "d888c16718067eabe7540f4d2573ffdda24887c9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "end = dt.datetime.now()\n",
    "print('Total time {} s.'.format((end - start).seconds))\n",
    "print('We almost used the one hour time limit.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
