{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from os import listdir, makedirs\n",
    "from os.path import join, exists, expanduser\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications import xception\n",
    "from keras.applications import inception_v3\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense, Dropout,Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10222 10222\n",
      "10357 10357\n"
     ]
    }
   ],
   "source": [
    "SEED = 1987\n",
    "data_dir = ''\n",
    "labels = pd.read_csv(join(data_dir, 'labels.csv'))\n",
    "sample_submission = pd.read_csv(join(data_dir, 'sample_submission.csv'))\n",
    "print(len(listdir(join(data_dir, 'train'))), len(labels))\n",
    "print(len(listdir(join(data_dir, 'test'))), len(sample_submission))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This part is optional for if you want to train only on most popular classes. \n",
    "# NUM_CLASSES = 16\n",
    "# selected_breed_list = list(labels.groupby('breed').count().sort_values(by='id', ascending=False).head(NUM_CLASSES).index)\n",
    "# labels = labels[labels['breed'].isin(selected_breed_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels['target'] = 1\n",
    "labels_pivot = labels.pivot('id', 'breed', 'target').reset_index().fillna(0)\n",
    "np.random.seed(seed=SEED)\n",
    "rnd = np.random.random(len(labels))\n",
    "train_idx = rnd < 0.8\n",
    "valid_idx = rnd >= 0.8\n",
    "labels_pivot = labels_pivot.drop('id', axis=1)\n",
    "y_train = labels_pivot.values\n",
    "ytr = y_train[train_idx]\n",
    "yv = y_train[valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_img(img_id, train_or_test, size):\n",
    "    \"\"\"Read and resize image.\n",
    "    # Arguments\n",
    "        img_id: string\n",
    "        train_or_test: string 'train' or 'test'.\n",
    "        size: resize the original image.\n",
    "    # Returns\n",
    "        Image as numpy array.\n",
    "    \"\"\"\n",
    "    img = image.load_img(join(data_dir, train_or_test, '%s.jpg' % img_id), target_size=size)\n",
    "    img = image.img_to_array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10222it [00:53, 191.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images shape: (10222, 299, 299, 3) size: 2,741,571,066\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = 299\n",
    "x_train = np.zeros((len(labels), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "for i, img_id in tqdm(enumerate(labels['id'])):\n",
    "    img = read_img(img_id, 'train', (INPUT_SIZE, INPUT_SIZE))\n",
    "    #x = xception.preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "    x_train[i] = img\n",
    "print('Train Images shape: {} size: {:,}'.format(x_train.shape, x_train.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((8140, 299, 299, 3), (2082, 299, 299, 3), (8140, 120), (2082, 120))\n"
     ]
    }
   ],
   "source": [
    "Xtr = x_train[train_idx]\n",
    "Xv = x_train[valid_idx]\n",
    "print((Xtr.shape, Xv.shape, ytr.shape, yv.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading Xception features\n",
    "xception_bottleneck = xception.Xception(weights='imagenet', include_top=False, pooling='avg')\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range = 0.3,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    horizontal_flip = True,\n",
    "    preprocessing_function = xception.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "generator = train_datagen.flow(Xtr, ytr, shuffle=False, batch_size=batch_size, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# xception_bottleneck_features = []\n",
    "# xception_labels = []\n",
    "# for i in range(len(Xtr) // batch_size):\n",
    "#     x, y = next(generator)\n",
    "#     xception_bottleneck_features.append(xception_bottleneck.predict(x))\n",
    "#     xception_labels.append(y) \n",
    "#     print(i,len(Xtr) // batch_size)\n",
    "\n",
    "# xception_bottleneck_features = np.concatenate(xception_bottleneck_features)\n",
    "# xception_labels = np.concatenate(xception_labels)\n",
    "xception_bottleneck_features = xception_bottleneck.predict_generator(generator)\n",
    "xception_labels=ytr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=1987, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xception_logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\n",
    "xception_logreg.fit(xception_bottleneck_features, (xception_labels * range(120)).sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function = xception.preprocess_input)\n",
    "generator = validation_datagen.flow(Xv, yv, shuffle=False, batch_size=batch_size, seed=SEED)\n",
    "xception_validation_features = xception_bottleneck.predict_generator(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Xception LogLoss 0.3515817905870127\n",
      "Validation Xception Accuracy 0.8952929875120077\n"
     ]
    }
   ],
   "source": [
    "valid_probs = xception_logreg.predict_proba(xception_validation_features)\n",
    "valid_preds = xception_logreg.predict(xception_validation_features)\n",
    "print('Validation Xception LogLoss {}'.format(log_loss(yv, valid_probs)))\n",
    "print('Validation Xception Accuracy {}'.format(accuracy_score((yv * range(120)).sum(axis=1), valid_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try Inception V3 module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Loading Inception features\n",
    "inception_v3_bottleneck = inception_v3.InceptionV3(weights='imagenet', include_top=False, pooling='avg')\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range = 0.3,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    horizontal_flip = True,\n",
    "    preprocessing_function = inception_v3.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255/255 [==============================] - ETA: 16:2 - ETA: 8:3 - ETA: 6: - ETA: 4: - ETA: 4: - ETA: 3: - ETA: 3: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 2: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 59s - ETA: 58 - ETA: 58 - ETA: 57 - ETA: 56 - ETA: 56 - ETA: 55 - ETA: 54 - ETA: 54 - ETA: 53 - ETA: 52 - ETA: 52 - ETA: 51 - ETA: 50 - ETA: 50 - ETA: 49 - ETA: 48 - ETA: 48 - ETA: 47 - ETA: 46 - ETA: 46 - ETA: 45 - ETA: 44 - ETA: 44 - ETA: 43 - ETA: 42 - ETA: 42 - ETA: 41 - ETA: 40 - ETA: 40 - ETA: 39 - ETA: 38 - ETA: 37 - ETA: 37 - ETA: 36 - ETA: 35 - ETA: 35 - ETA: 34 - ETA: 33 - ETA: 33 - ETA: 32 - ETA: 31 - ETA: 31 - ETA: 30 - ETA: 29 - ETA: 29 - ETA: 28 - ETA: 27 - ETA: 27 - ETA: 26 - ETA: 25 - ETA: 25 - ETA: 24 - ETA: 23 - ETA: 23 - ETA: 22 - ETA: 21 - ETA: 20 - ETA: 20 - ETA: 19 - ETA: 18 - ETA: 18 - ETA: 17 - ETA: 16 - ETA: 16 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 172s 676ms/step\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "generator = train_datagen.flow(Xtr, ytr, shuffle=False, batch_size=batch_size, seed=SEED)\n",
    "\n",
    "# inception_v3_bottleneck_features = []\n",
    "# inception_v3_labels = []\n",
    "# for i in range(len(Xtr) // batch_size):\n",
    "#     x, y = next(generator)\n",
    "#     inception_v3_bottleneck_features.append(inception_v3_bottleneck.predict(x))\n",
    "#     inception_v3_labels.append(y) \n",
    "#     print(i,len(Xtr) // batch_size)\n",
    "\n",
    "# inception_v3_bottleneck = np.concatenate(inception_v3_bottleneck)\n",
    "# inception_v3_labels = np.concatenate(inception_v3_labels)\n",
    "inception_v3_bottleneck_features = inception_v3_bottleneck.predict_generator(generator,verbose=1)\n",
    "inception_v3_labels=ytr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=1987, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception_v3_logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\n",
    "inception_v3_logreg.fit(inception_v3_bottleneck_features, (inception_v3_labels * range(120)).sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function = inception_v3.preprocess_input)\n",
    "generator = validation_datagen.flow(Xv, yv, shuffle=False, batch_size=batch_size, seed=SEED)\n",
    "inception_v3_validation_features = inception_v3_bottleneck.predict_generator(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Xception LogLoss 0.36028253045998804\n",
      "Validation Xception Accuracy 0.8928914505283382\n"
     ]
    }
   ],
   "source": [
    "valid_probs = inception_v3_logreg.predict_proba(inception_v3_validation_features)\n",
    "valid_preds = inception_v3_logreg.predict(inception_v3_validation_features)\n",
    "print('Validation Xception LogLoss {}'.format(log_loss(yv, valid_probs)))\n",
    "print('Validation Xception Accuracy {}'.format(accuracy_score((yv * range(120)).sum(axis=1), valid_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Try to stack the features of Xception and Inception and see how that works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full train bottleneck features shape: (8140, 4096) size: 33,341,440\n",
      "Full valid bottleneck features shape: (2082, 4096) size: 8,527,872\n",
      "Validation Xception + Inception LogLoss 0.31424559722120965\n",
      "Validation Xception + Inception Accuracy 0.9087415946205571\n"
     ]
    }
   ],
   "source": [
    "X = np.hstack([xception_bottleneck_features, inception_v3_bottleneck_features])\n",
    "V = np.hstack([xception_validation_features, inception_v3_validation_features])\n",
    "print('Full train bottleneck features shape: {} size: {:,}'.format(X.shape, X.size))\n",
    "print('Full valid bottleneck features shape: {} size: {:,}'.format(V.shape, V.size))\n",
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\n",
    "logreg.fit(X, (ytr * range(120)).sum(axis=1))\n",
    "valid_probs = logreg.predict_proba(V)\n",
    "valid_preds = logreg.predict(V)\n",
    "print('Validation Xception + Inception LogLoss {}'.format(log_loss(yv, valid_probs)))\n",
    "print('Validation Xception + Inception Accuracy {}'.format(accuracy_score((yv * range(120)).sum(axis=1), valid_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def generate_features(model_info, data, labels, datagen):\n",
    "#     print(\"generating features...\")\n",
    "#     datagen.preprocessing_function = model_info[\"preprocessor\"]\n",
    "#     generator = datagen.flow(data, labels, shuffle=False, batch_size=batch_size, seed=model_info[\"seed\"])\n",
    "#     bottleneck_model = model_info[\"model\"](weights='imagenet', include_top=False, input_shape=model_info[\"input_shape\"], pooling=model_info[\"pooling\"])\n",
    "#     return bottleneck_model.predict_generator(generator)\n",
    "\n",
    "# models = {\n",
    "#     \"InceptionV3\": {\n",
    "#         \"model\": InceptionV3,\n",
    "#         \"preprocessor\": inception_v3_preprocessor,\n",
    "#         \"input_shape\": (299,299,3),\n",
    "#         \"seed\": 1234,\n",
    "#         \"pooling\": \"avg\"\n",
    "#     },\n",
    "#     \"Xception\": {\n",
    "#         \"model\": Xception,\n",
    "#         \"preprocessor\": xception_preprocessor,\n",
    "#         \"input_shape\": (299,299,3),\n",
    "#         \"seed\": 5512,\n",
    "#         \"pooling\": \"avg\"\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Creating submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10357it [16:30, 10.46it/s]\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = 224\n",
    "for i, img_id in tqdm(enumerate(sample_submission['id'])):\n",
    "    img = read_img(img_id, 'test', (INPUT_SIZE, INPUT_SIZE))\n",
    "    x1 = inception_v3.preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "    x2 = xception.preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "    y1 = inception_v3_bottleneck.predict(x1)\n",
    "    y2 = xception_bottleneck.predict(x2)\n",
    "    y3=np.hstack([y2, y1])\n",
    "    P = logreg.predict(y3)\n",
    "    y=np.zeros((1,120))\n",
    "    y[0,P.astype('int')-1]=1\n",
    "    sample_submission.iloc[i,1:121] = np.asarray(y[0,0:120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sample_submission.iloc[1,1:121] = np.asarray(y[0,0:120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv('submission6.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>affenpinscher</th>\n",
       "      <th>afghan_hound</th>\n",
       "      <th>african_hunting_dog</th>\n",
       "      <th>airedale</th>\n",
       "      <th>american_staffordshire_terrier</th>\n",
       "      <th>appenzeller</th>\n",
       "      <th>australian_terrier</th>\n",
       "      <th>basenji</th>\n",
       "      <th>basset</th>\n",
       "      <th>...</th>\n",
       "      <th>toy_poodle</th>\n",
       "      <th>toy_terrier</th>\n",
       "      <th>vizsla</th>\n",
       "      <th>walker_hound</th>\n",
       "      <th>weimaraner</th>\n",
       "      <th>welsh_springer_spaniel</th>\n",
       "      <th>west_highland_white_terrier</th>\n",
       "      <th>whippet</th>\n",
       "      <th>wire-haired_fox_terrier</th>\n",
       "      <th>yorkshire_terrier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000621fb3cbb32d8935728e48679680e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00102ee9d8eb90812350685311fe5890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012a730dfa437f5f3613fb75efcd4ce</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001510bc8570bbeee98c8d80c8a95ec1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001a5f3114548acdefa3d4da05474c2e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  affenpinscher  afghan_hound  \\\n",
       "0  000621fb3cbb32d8935728e48679680e            0.0           0.0   \n",
       "1  00102ee9d8eb90812350685311fe5890            0.0           0.0   \n",
       "2  0012a730dfa437f5f3613fb75efcd4ce            0.0           0.0   \n",
       "3  001510bc8570bbeee98c8d80c8a95ec1            0.0           0.0   \n",
       "4  001a5f3114548acdefa3d4da05474c2e            0.0           0.0   \n",
       "\n",
       "   african_hunting_dog  airedale  american_staffordshire_terrier  appenzeller  \\\n",
       "0                  0.0       0.0                             0.0          0.0   \n",
       "1                  0.0       0.0                             0.0          0.0   \n",
       "2                  0.0       0.0                             0.0          0.0   \n",
       "3                  0.0       0.0                             0.0          0.0   \n",
       "4                  0.0       0.0                             0.0          0.0   \n",
       "\n",
       "   australian_terrier  basenji  basset        ...          toy_poodle  \\\n",
       "0                 0.0      0.0     0.0        ...                 0.0   \n",
       "1                 0.0      0.0     0.0        ...                 0.0   \n",
       "2                 0.0      0.0     0.0        ...                 0.0   \n",
       "3                 0.0      0.0     0.0        ...                 0.0   \n",
       "4                 0.0      0.0     0.0        ...                 0.0   \n",
       "\n",
       "   toy_terrier  vizsla  walker_hound  weimaraner  welsh_springer_spaniel  \\\n",
       "0          0.0     0.0           0.0         0.0                     0.0   \n",
       "1          0.0     0.0           0.0         0.0                     0.0   \n",
       "2          0.0     0.0           0.0         0.0                     0.0   \n",
       "3          0.0     0.0           0.0         0.0                     0.0   \n",
       "4          0.0     0.0           0.0         0.0                     0.0   \n",
       "\n",
       "   west_highland_white_terrier  whippet  wire-haired_fox_terrier  \\\n",
       "0                          0.0      0.0                      0.0   \n",
       "1                          0.0      0.0                      0.0   \n",
       "2                          0.0      0.0                      0.0   \n",
       "3                          0.0      0.0                      0.0   \n",
       "4                          0.0      0.0                      0.0   \n",
       "\n",
       "   yorkshire_terrier  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                0.0  \n",
       "3                0.0  \n",
       "4                0.0  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
